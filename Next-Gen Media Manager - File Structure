# Next-Gen Media Manager - File Structure

## Project Structure
```
NextGenMediaManager/
├── NextGenMediaManagerApp.swift
├── Models/
│   ├── MediaItem.swift
│   └── SmartCollection.swift
├── ViewModels/
│   ├── PhotoLibraryManager.swift
│   ├── AIProcessor.swift
│   └── SearchManager.swift
├── Views/
│   ├── ContentView.swift
│   ├── Onboarding/
│   │   ├── OnboardingView.swift
│   │   └── FeatureRow.swift
│   ├── Main/
│   │   ├── MainTabView.swift
│   │   ├── TimelineView.swift
│   │   ├── SmartCollectionsView.swift
│   │   ├── SearchView.swift
│   │   └── SettingsView.swift
│   └── Components/
│       ├── MediaThumbnailView.swift
│       ├── SmartCollectionCard.swift
│       └── ProcessingView.swift
└── Utilities/
    └── TimeRange.swift
```

## File Contents

### 1. NextGenMediaManagerApp.swift
```swift
import SwiftUI

@main
struct NextGenMediaManagerApp: App {
    @StateObject private var photoLibraryManager = PhotoLibraryManager()
    @StateObject private var aiProcessor = AIProcessor()
    @StateObject private var searchManager = SearchManager()
    
    var body: some Scene {
        WindowGroup {
            ContentView()
                .environmentObject(photoLibraryManager)
                .environmentObject(aiProcessor)
                .environmentObject(searchManager)
        }
    }
}
```

### 2. Models/MediaItem.swift
```swift
import Foundation
import Photos
import CoreLocation
import UIKit

struct MediaItem: Identifiable {
    let id = UUID()
    let asset: PHAsset
    var thumbnail: UIImage?
    var tags: Set<String> = []
    var people: [String] = []
    var location: CLLocation?
    var textContent: String = ""
    var dominantColors: [UIColor] = []
    var scene: String = ""
    var eventType: String = ""
}
```

### 3. Models/SmartCollection.swift
```swift
import Foundation
import UIKit

struct SmartCollection: Identifiable {
    let id = UUID()
    let name: String
    let coverImage: UIImage?
    let mediaItems: [MediaItem]
    let aiGeneratedTheme: String
}
```

### 4. ViewModels/PhotoLibraryManager.swift
```swift
import SwiftUI
import Photos
import Combine

class PhotoLibraryManager: ObservableObject {
    @Published var mediaItems: [MediaItem] = []
    @Published var authorizationStatus: PHAuthorizationStatus = .notDetermined
    @Published var isProcessing = false
    @Published var processingProgress: Double = 0.0
    
    func requestAuthorization() async {
        let status = await PHPhotoLibrary.requestAuthorization(for: .readWrite)
        await MainActor.run {
            self.authorizationStatus = status
        }
    }
    
    func loadMediaItems() async {
        guard authorizationStatus == .authorized else { return }
        
        await MainActor.run {
            isProcessing = true
        }
        
        let fetchOptions = PHFetchOptions()
        fetchOptions.sortDescriptors = [NSSortDescriptor(key: "creationDate", ascending: false)]
        fetchOptions.includeAssetSourceTypes = [.typeUserLibrary, .typeCloudShared]
        
        let assets = PHAsset.fetchAssets(with: fetchOptions)
        var items: [MediaItem] = []
        
        assets.enumerateObjects { asset, index, _ in
            let item = MediaItem(
                asset: asset,
                location: asset.location
            )
            items.append(item)
            
            Task { @MainActor in
                self.processingProgress = Double(index) / Double(assets.count)
            }
        }
        
        await MainActor.run {
            self.mediaItems = items
            self.isProcessing = false
        }
    }
}
```

### 5. ViewModels/AIProcessor.swift
```swift
import SwiftUI
import Vision
import CoreML
import Photos

class AIProcessor: ObservableObject {
    @Published var isAnalyzing = false
    @Published var analysisProgress: Double = 0.0
    
    func analyzeMediaItem(_ item: MediaItem) async -> MediaItem {
        var updatedItem = item
        
        // Image analysis using Vision framework
        guard let image = await loadImage(from: item.asset) else { return item }
        
        // Object Detection
        if let objects = await detectObjects(in: image) {
            updatedItem.tags.formUnion(objects)
        }
        
        // Face Detection
        if let faces = await detectFaces(in: image) {
            updatedItem.people = faces
        }
        
        // Text Recognition (OCR)
        if let text = await recognizeText(in: image) {
            updatedItem.textContent = text
        }
        
        // Scene Classification
        if let scene = await classifyScene(in: image) {
            updatedItem.scene = scene
            updatedItem.tags.insert(scene)
        }
        
        return updatedItem
    }
    
    private func loadImage(from asset: PHAsset) async -> UIImage? {
        return await withCheckedContinuation { continuation in
            let options = PHImageRequestOptions()
            options.isSynchronous = true
            options.deliveryMode = .highQualityFormat
            
            PHImageManager.default().requestImage(
                for: asset,
                targetSize: CGSize(width: 1024, height: 1024),
                contentMode: .aspectFit,
                options: options
            ) { image, _ in
                continuation.resume(returning: image)
            }
        }
    }
    
    private func detectObjects(in image: UIImage) async -> Set<String>? {
        // TODO: Implement Vision object detection
        // This is a placeholder - implement actual Vision requests
        return ["person", "dog", "tree", "car"]
    }
    
    private func detectFaces(in image: UIImage) async -> [String]? {
        // TODO: Implement Vision face detection
        return ["Person 1", "Person 2"]
    }
    
    private func recognizeText(in image: UIImage) async -> String? {
        // TODO: Implement Vision text recognition
        return "Sample detected text"
    }
    
    private func classifyScene(in image: UIImage) async -> String? {
        // TODO: Implement Vision scene classification
        return "outdoor"
    }
}
```

### 6. ViewModels/SearchManager.swift
```swift
import SwiftUI
import Combine

class SearchManager: ObservableObject {
    @Published var searchText = ""
    @Published var searchResults: [MediaItem] = []
    @Published var isSearching = false
    @Published var searchMode: SearchMode = .natural
    
    enum SearchMode {
        case natural, advanced, voice
    }
    
    func performSearch(query: String, in items: [MediaItem]) async {
        await MainActor.run {
            isSearching = true
        }
        
        // Natural language processing for search
        let processedQuery = processNaturalLanguageQuery(query)
        
        // Filter items based on query
        let results = items.filter { item in
            // Check tags
            if item.tags.contains(where: { $0.localizedCaseInsensitiveContains(processedQuery) }) {
                return true
            }
            
            // Check text content
            if item.textContent.localizedCaseInsensitiveContains(processedQuery) {
                return true
            }
            
            // Check people
            if item.people.contains(where: { $0.localizedCaseInsensitiveContains(processedQuery) }) {
                return true
            }
            
            // Check scene
            if item.scene.localizedCaseInsensitiveContains(processedQuery) {
                return true
            }
            
            return false
        }
        
        await MainActor.run {
            self.searchResults = results
            self.isSearching = false
        }
    }
    
    private func processNaturalLanguageQuery(_ query: String) -> String {
        // Simple natural language processing
        // TODO: In production, use NLLanguageRecognizer and NLTagger
        return query.lowercased()
            .replacingOccurrences(of: "show me", with: "")
            .replacingOccurrences(of: "find", with: "")
            .replacingOccurrences(of: "photos of", with: "")
            .replacingOccurrences(of: "pictures of", with: "")
            .trimmingCharacters(in: .whitespacesAndNewlines)
    }
}
```

### 7. Views/ContentView.swift
```swift
import SwiftUI

struct ContentView: View {
    @EnvironmentObject var photoLibraryManager: PhotoLibraryManager
    @State private var showOnboarding = true
    @State private var selectedTab = 0
    
    var body: some View {
        Group {
            if showOnboarding && photoLibraryManager.authorizationStatus != .authorized {
                OnboardingView(showOnboarding: $showOnboarding)
            } else {
                MainTabView(selectedTab: $selectedTab)
            }
        }
    }
}
```

### 8. Views/Onboarding/OnboardingView.swift
```swift
import SwiftUI
import Photos

struct OnboardingView: View {
    @Binding var showOnboarding: Bool
    @EnvironmentObject var photoLibraryManager: PhotoLibraryManager
    @State private var currentPage = 0
    
    var body: some View {
        VStack {
            TabView(selection: $currentPage) {
                // Welcome Screen
                VStack(spacing: 24) {
                    Image(systemName: "photo.stack.fill")
                        .font(.system(size: 80))
                        .foregroundColor(.blue)
                    
                    Text("Welcome to Next-Gen Media Manager")
                        .font(.largeTitle)
                        .fontWeight(.bold)
                    
                    Text("Your intelligent photo companion")
                        .font(.title3)
                        .foregroundColor(.secondary)
                }
                .tag(0)
                
                // Features Screen
                VStack(spacing: 32) {
                    Text("Smart Features")
                        .font(.largeTitle)
                        .fontWeight(.bold)
                    
                    FeatureRow(icon: "magnifyingglass.circle.fill", 
                               title: "AI-Powered Search",
                               description: "Find photos using natural language")
                    
                    FeatureRow(icon: "sparkles", 
                               title: "Smart Collections",
                               description: "Automatically organized memories")
                    
                    FeatureRow(icon: "text.viewfinder", 
                               title: "Text Recognition",
                               description: "Search text within your photos")
                }
                .padding(.horizontal)
                .tag(1)
                
                // Permission Screen
                VStack(spacing: 32) {
                    Image(systemName: "lock.shield.fill")
                        .font(.system(size: 80))
                        .foregroundColor(.green)
                    
                    Text("Your Privacy Matters")
                        .font(.largeTitle)
                        .fontWeight(.bold)
                    
                    Text("We need access to your photos to analyze them. All processing happens on your device.")
                        .font(.body)
                        .multilineTextAlignment(.center)
                        .padding(.horizontal)
                    
                    Button(action: {
                        Task {
                            await photoLibraryManager.requestAuthorization()
                            if photoLibraryManager.authorizationStatus == .authorized {
                                showOnboarding = false
                                await photoLibraryManager.loadMediaItems()
                            }
                        }
                    }) {
                        Label("Grant Access", systemImage: "checkmark.circle.fill")
                            .font(.headline)
                            .foregroundColor(.white)
                            .frame(maxWidth: .infinity)
                            .padding()
                            .background(Color.blue)
                            .cornerRadius(12)
                    }
                    .padding(.horizontal, 40)
                }
                .tag(2)
            }
            .tabViewStyle(PageTabViewStyle())
            
            // Page Indicator
            HStack(spacing: 8) {
                ForEach(0..<3) { index in
                    Circle()
                        .fill(currentPage == index ? Color.blue : Color.gray.opacity(0.3))
                        .frame(width: 8, height: 8)
                }
            }
            .padding(.bottom, 20)
        }
    }
}
```

### 9. Views/Onboarding/FeatureRow.swift
```swift
import SwiftUI

struct FeatureRow: View {
    let icon: String
    let title: String
    let description: String
    
    var body: some View {
        HStack(spacing: 16) {
            Image(systemName: icon)
                .font(.system(size: 40))
                .foregroundColor(.blue)
                .frame(width: 60)
            
            VStack(alignment: .leading, spacing: 4) {
                Text(title)
                    .font(.headline)
                Text(description)
                    .font(.subheadline)
                    .foregroundColor(.secondary)
            }
            
            Spacer()
        }
    }
}
```

### 10. Views/Main/MainTabView.swift
```swift
import SwiftUI

struct MainTabView: View {
    @Binding var selectedTab: Int
    
    var body: some View {
        TabView(selection: $selectedTab) {
            TimelineView()
                .tabItem {
                    Label("Timeline", systemImage: "clock.fill")
                }
                .tag(0)
            
            SmartCollectionsView()
                .tabItem {
                    Label("Collections", systemImage: "square.stack.3d.up.fill")
                }
                .tag(1)
            
            SearchView()
                .tabItem {
                    Label("Search", systemImage: "magnifyingglass")
                }
                .tag(2)
            
            SettingsView()
                .tabItem {
                    Label("Settings", systemImage: "gear")
                }
                .tag(3)
        }
    }
}
```

### 11. Views/Main/TimelineView.swift
```swift
import SwiftUI
import Photos

struct TimelineView: View {
    @EnvironmentObject var photoLibraryManager: PhotoLibraryManager
    @State private var selectedTimeRange = TimeRange.all
    
    var body: some View {
        NavigationView {
            ScrollView {
                if photoLibraryManager.isProcessing {
                    ProcessingView(progress: photoLibraryManager.processingProgress)
                } else {
                    LazyVGrid(columns: [
                        GridItem(.adaptive(minimum: 100), spacing: 2)
                    ], spacing: 2) {
                        ForEach(filteredMediaItems) { item in
                            MediaThumbnailView(mediaItem: item)
                        }
                    }
                }
            }
            .navigationTitle("Timeline")
            .toolbar {
                ToolbarItem(placement: .navigationBarTrailing) {
                    Menu {
                        ForEach(TimeRange.allCases, id: \.self) { range in
                            Button(range.rawValue) {
                                selectedTimeRange = range
                            }
                        }
                    } label: {
                        Label(selectedTimeRange.rawValue, systemImage: "calendar")
                    }
                }
            }
        }
    }
    
    var filteredMediaItems: [MediaItem] {
        // TODO: Filter based on selected time range
        return photoLibraryManager.mediaItems
    }
}
```

### 12. Views/Main/SmartCollectionsView.swift
```swift
import SwiftUI

struct SmartCollectionsView: View {
    @State private var collections: [SmartCollection] = []
    
    var body: some View {
        NavigationView {
            ScrollView {
                LazyVGrid(columns: [
                    GridItem(.adaptive(minimum: 150), spacing: 16)
                ], spacing: 16) {
                    ForEach(collections) { collection in
                        SmartCollectionCard(collection: collection)
                    }
                }
                .padding()
            }
            .navigationTitle("Smart Collections")
        }
    }
}
```

### 13. Views/Main/SearchView.swift
```swift
import SwiftUI

struct SearchView: View {
    @EnvironmentObject var searchManager: SearchManager
    @State private var isVoiceSearchActive = false
    
    var body: some View {
        NavigationView {
            VStack {
                // Search Bar
                HStack {
                    Image(systemName: "magnifyingglass")
                        .foregroundColor(.secondary)
                    
                    TextField("Search photos...", text: $searchManager.searchText)
                        .textFieldStyle(RoundedBorderTextFieldStyle())
                    
                    Button(action: { isVoiceSearchActive.toggle() }) {
                        Image(systemName: "mic.fill")
                            .foregroundColor(isVoiceSearchActive ? .red : .blue)
                    }
                }
                .padding()
                
                // Search Results
                if searchManager.isSearching {
                    ProgressView("Searching...")
                        .frame(maxHeight: .infinity)
                } else if !searchManager.searchResults.isEmpty {
                    ScrollView {
                        LazyVGrid(columns: [
                            GridItem(.adaptive(minimum: 100), spacing: 2)
                        ], spacing: 2) {
                            ForEach(searchManager.searchResults) { item in
                                MediaThumbnailView(mediaItem: item)
                            }
                        }
                    }
                } else if !searchManager.searchText.isEmpty {
                    Text("No results found")
                        .foregroundColor(.secondary)
                        .frame(maxHeight: .infinity)
                } else {
                    // Search suggestions
                    VStack(alignment: .leading, spacing: 16) {
                        Text("Try searching for:")
                            .font(.headline)
                            .padding(.horizontal)
                        
                        ForEach(["Beach photos", "Family gatherings", "Text in photos", "Sunset pictures"], id: \.self) { suggestion in
                            Button(action: {
                                searchManager.searchText = suggestion
                            }) {
                                HStack {
                                    Image(systemName: "magnifyingglass")
                                    Text(suggestion)
                                    Spacer()
                                }
                                .padding()
                                .background(Color.gray.opacity(0.1))
                                .cornerRadius(8)
                            }
                            .padding(.horizontal)
                        }
                        
                        Spacer()
                    }
                    .padding(.top)
                }
            }
            .navigationTitle("Search")
        }
    }
}
```

### 14. Views/Main/SettingsView.swift
```swift
import SwiftUI

struct SettingsView: View {
    @State private var useICloud = true
    @State private var useLocalStorage = true
    @State private var enableBackgroundProcessing = true
    @State private var prioritizeRecentPhotos = true
    
    var body: some View {
        NavigationView {
            Form {
                Section("Storage") {
                    Toggle("Use iCloud Photos", isOn: $useICloud)
                    Toggle("Use Local Storage", isOn: $useLocalStorage)
                }
                
                Section("Processing") {
                    Toggle("Background Processing", isOn: $enableBackgroundProcessing)
                    Toggle("Prioritize Recent Photos", isOn: $prioritizeRecentPhotos)
                }
                
                Section("About") {
                    HStack {
                        Text("Version")
                        Spacer()
                        Text("1.0.0")
                            .foregroundColor(.secondary)
                    }
                    
                    Link("Privacy Policy", destination: URL(string: "https://example.com/privacy")!)
                }
            }
            .navigationTitle("Settings")
        }
    }
}
```

### 15. Views/Components/MediaThumbnailView.swift
```swift
import SwiftUI
import Photos

struct MediaThumbnailView: View {
    let mediaItem: MediaItem
    @State private var thumbnail: UIImage?
    
    var body: some View {
        ZStack {
            if let image = thumbnail {
                Image(uiImage: image)
                    .resizable()
                    .aspectRatio(contentMode: .fill)
                    .frame(width: 100, height: 100)
                    .clipped()
            } else {
                Rectangle()
                    .fill(Color.gray.opacity(0.3))
                    .frame(width: 100, height: 100)
                    .overlay(
                        ProgressView()
                            .scaleEffect(0.5)
                    )
            }
            
            // Overlay for video indicator
            if mediaItem.asset.mediaType == .video {
                Image(systemName: "play.circle.fill")
                    .font(.title2)
                    .foregroundColor(.white)
                    .shadow(radius: 2)
            }
        }
        .onAppear {
            loadThumbnail()
        }
    }
    
    private func loadThumbnail() {
        let options = PHImageRequestOptions()
        options.deliveryMode = .opportunistic
        
        PHImageManager.default().requestImage(
            for: mediaItem.asset,
            targetSize: CGSize(width: 200, height: 200),
            contentMode: .aspectFill,
            options: options
        ) { image, _ in
            self.thumbnail = image
        }
    }
}
```

### 16. Views/Components/SmartCollectionCard.swift
```swift
import SwiftUI

struct SmartCollectionCard: View {
    let collection: SmartCollection
    
    var body: some View {
        VStack(alignment: .leading, spacing: 8) {
            // Cover image
            if let coverImage = collection.coverImage {
                Image(uiImage: coverImage)
                    .resizable()
                    .aspectRatio(contentMode: .fill)
                    .frame(height: 120)
                    .clipped()
                    .cornerRadius(8)
            } else {
                RoundedRectangle(cornerRadius: 8)
                    .fill(Color.gray.opacity(0.3))
                    .frame(height: 120)
            }
            
            Text(collection.name)
                .font(.headline)
                .lineLimit(1)
            
            Text("\(collection.mediaItems.count) items")
                .font(.caption)
                .foregroundColor(.secondary)
        }
    }
}
```

### 17. Views/Components/ProcessingView.swift
```swift
import SwiftUI

struct ProcessingView: View {
    let progress: Double
    
    var body: some View {
        VStack(spacing: 20) {
            ProgressView(value: progress)
                .progressViewStyle(LinearProgressViewStyle())
                .padding(.horizontal, 40)
            
            Text("Processing your photos...")
                .font(.headline)
            
            Text("\(Int(progress * 100))% complete")
                .foregroundColor(.secondary)
        }
        .padding(.vertical, 100)
    }
}
```

### 18. Utilities/TimeRange.swift
```swift
import Foundation

enum TimeRange: String, CaseIterable {
    case all = "All"
    case today = "Today"
    case week = "This Week"
    case month = "This Month"
    case year = "This Year"
}
```

## Setup Instructions

1. Create a new Xcode project with SwiftUI
2. Create the folder structure as shown above
3. Copy each file content into its respective file
4. Add the following to your Info.plist:
```xml
<key>NSPhotoLibraryUsageDescription</key>
<string>This app needs access to your photos to analyze and organize them using AI.</string>
```

5. Enable the following capabilities in your project:
   - Photo Library Access
   - Background Modes (for background processing)

## Next Steps
- Implement the TODO sections in AIProcessor.swift with actual Vision framework code
- Add Core ML models for enhanced image analysis
- Implement the time-based filtering in TimelineView
- Add background task scheduling for photo processing
- Implement voice search functionality
- Add unit tests for ViewModels
